{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dopamine_need_term_experiment.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F2BCg47OtiN"
      },
      "source": [
        "# Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbNugu9FgDau"
      },
      "source": [
        "# @title Install necessary packages.\n",
        "!pip install -U dopamine-rl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr3FQTM94_Lh"
      },
      "source": [
        "# @title Install Atari ROMS from google drive\n",
        "!python -m atari_py.import_roms drive/MyDrive/Dopamine-need\\ experiments/ROMS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjpZ5I6pgRkb"
      },
      "source": [
        "# @title Necessary imports and globals.\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from dopamine.agents.dqn import dqn_agent\n",
        "from dopamine.discrete_domains import run_experiment\n",
        "from dopamine.colab import utils as colab_utils\n",
        "from absl import flags\n",
        "import gin.tf\n",
        "\n",
        "BASE_PATH = '/tmp/colab_dope_run'  # @param\n",
        "GAME = 'Asterix'  # @param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO45bT1TgTzM"
      },
      "source": [
        "# @title Load baseline data\n",
        "!gsutil -q -m cp -R gs://download-dopamine-rl/preprocessed-benchmarks/* /content/\n",
        "experimental_data = colab_utils.load_baselines('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIeo-Fp_O0D5"
      },
      "source": [
        "# DQN Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p27FlitLm3Fc"
      },
      "source": [
        "# @title Create an agent based on DQN, but choosing actions randomly.\n",
        "\n",
        "LOG_PATH = os.path.join(BASE_PATH, 'random_dqn', GAME)\n",
        "\n",
        "class MyRandomDQNAgent(dqn_agent.DQNAgent):\n",
        "  def __init__(self, sess, num_actions):\n",
        "    \"\"\"This maintains all the DQN default argument values.\"\"\"\n",
        "    super().__init__(sess, num_actions)\n",
        "\n",
        "  def step(self, reward, observation):\n",
        "    \"\"\"Calls the step function of the parent class, but returns a random action.\n",
        "    \"\"\"\n",
        "    super().step(reward, observation)\n",
        "    return np.random.randint(self.num_actions)\n",
        "\n",
        "def create_random_dqn_agent(sess, environment, summary_writer=None):\n",
        "  \"\"\"The Runner class will expect a function of this type to create an agent.\"\"\"\n",
        "  return MyRandomDQNAgent(sess, num_actions=environment.action_space.n)\n",
        "\n",
        "random_dqn_config = \"\"\"\n",
        "import dopamine.discrete_domains.atari_lib\n",
        "import dopamine.discrete_domains.run_experiment\n",
        "atari_lib.create_atari_environment.game_name = '{}'\n",
        "atari_lib.create_atari_environment.sticky_actions = True\n",
        "run_experiment.Runner.num_iterations = 200\n",
        "run_experiment.Runner.training_steps = 10\n",
        "run_experiment.Runner.max_steps_per_episode = 100\n",
        "\"\"\".format(GAME)\n",
        "gin.parse_config(random_dqn_config, skip_unknown=False)\n",
        "\n",
        "# Create the runner class with this agent. We use very small numbers of steps\n",
        "# to terminate quickly, as this is mostly meant for demonstrating how one can\n",
        "# use the framework.\n",
        "random_dqn_runner = run_experiment.TrainRunner(LOG_PATH, create_random_dqn_agent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNk4JG7ymHF6"
      },
      "source": [
        "# @title Train MyRandomDQNAgent.\n",
        "print('Will train agent, please be patient, may be a while...')\n",
        "random_dqn_runner.run_experiment()\n",
        "print('Done training!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9yKWjZ2p1PU"
      },
      "source": [
        "# @title Load the training logs.\n",
        "random_dqn_data = colab_utils.read_experiment(\n",
        "    LOG_PATH, verbose=True, summary_keys=['train_episode_returns'])\n",
        "random_dqn_data['agent'] = 'MyRandomDQN'\n",
        "random_dqn_data['run_number'] = 1\n",
        "experimental_data[GAME] = experimental_data[GAME].merge(random_dqn_data, how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxIKkvcYb_Ze"
      },
      "source": [
        "# @title Plot training results.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,8))\n",
        "sns.lineplot(\n",
        "    x='iteration', y='train_episode_returns', hue='agent',\n",
        "    data=experimental_data[GAME], ax=ax)\n",
        "plt.title(GAME)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvlTsNW3O3kr"
      },
      "source": [
        "# DQN Prioritized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRRojVf8pe8b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de0B3_FAO71g"
      },
      "source": [
        "# Upload to Git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEZwD_xaO_qS"
      },
      "source": [
        "\n",
        "\n",
        "1.   manually clone the repo to local computer\n",
        "2.   download this file and overwrite into the repo\n",
        "3.   resolve conflicts, push to origin\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FonEuShjO-cJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}