{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Necessary imports and globals.\n",
    "import numpy as np\n",
    "import os\n",
    "import dopamine\n",
    "from dopamine.agents.dqn import dqn_agent\n",
    "from dopamine.discrete_domains import run_experiment, atari_lib\n",
    "from dopamine.colab import utils as colab_utils\n",
    "from absl import flags\n",
    "import gin.tf\n",
    "\n",
    "BASE_PATH = 'running-data'  # @param\n",
    "GAME = 'BattleZone'  # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data = colab_utils.load_baselines('./baselines-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = os.path.join(BASE_PATH, 'prioritized_srdqn', GAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished constructing\n",
      "Model: \"Online\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv (Conv2D)                multiple                  8224      \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  32832     \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  36928     \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  3965440   \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  9234      \n",
      "=================================================================\n",
      "Total params: 4,052,658\n",
      "Trainable params: 4,052,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sr_network_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv (Conv2D)                multiple                  8224      \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  32832     \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  36928     \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  231211520 \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  524800    \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  2097408   \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  524416    \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  131136    \n",
      "_________________________________________________________________\n",
      "Conv (Conv2D)                multiple                  4100      \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  262656    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131328    \n",
      "_________________________________________________________________\n",
      "fully_connected (Dense)      multiple                  131584    \n",
      "=================================================================\n",
      "Total params: 244,031,588\n",
      "Trainable params: 244,031,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [451584,512] and type float\n\t [[node sr_network_3/fully_connected/kernel/RMSProp/Initializer/ones (defined at C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'sr_network_3/fully_connected/kernel/RMSProp/Initializer/ones':\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 243, in <module>\n    prioritized_srdqn_runner = run_experiment.TrainRunner(LOG_PATH, create_prioritized_srdqn_agent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 553, in __init__\n    create_environment_fn)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 219, in __init__\n    summary_writer=self._summary_writer)\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 200, in create_prioritized_srdqn_agent\n    return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 15, in __init__\n    self._sr_train_op = self._build_sr_train_op()\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 90, in _build_sr_train_op\n    return self.optimizer.minimize(tf.reduce_mean(loss))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 413, in minimize\n    name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 597, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\rmsprop.py\", line 124, in _create_slots\n    self._name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 1135, in _get_or_make_slot_with_initializer\n    var, initializer, shape, dtype, op_name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 164, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 74, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 905, in <lambda>\n    partition_info=partition_info)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py\", line 134, in __call__\n    return array_ops.ones(shape, dtype)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2572, in ones\n    output = fill(shape, constant(one, dtype=dtype), name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 171, in fill\n    result = gen_array_ops.fill(dims, value, name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 3602, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n  In call to configurable 'Runner' (<class 'dopamine.discrete_domains.run_experiment.Runner'>)\n  In call to configurable 'TrainRunner' (<class 'dopamine.discrete_domains.run_experiment.TrainRunner'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-af31c869d19d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;31m# to terminate quickly, as this is mostly meant for demonstrating how one can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;31m# use the framework.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m \u001b[0mprioritized_srdqn_runner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainRunner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_prioritized_srdqn_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1067\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" in scope '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m       \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[1;34m(exception, message)\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, base_dir, create_agent_fn, create_environment_fn)\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Creating TrainRunner ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     super(TrainRunner, self).__init__(base_dir, create_agent_fn,\n\u001b[1;32m--> 553\u001b[1;33m                                       create_environment_fn)\n\u001b[0m\u001b[0;32m    554\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1067\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" in scope '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m       \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[1;34m(exception, message)\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, base_dir, create_agent_fn, create_environment_fn, checkpoint_file_prefix, logging_file_prefix, log_every_n, num_iterations, training_steps, evaluation_steps, max_steps_per_episode, clip_rewards)\u001b[0m\n\u001b[0;32m    219\u001b[0m                                   summary_writer=self._summary_writer)\n\u001b[0;32m    220\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_checkpointer_and_maybe_resume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_file_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [451584,512] and type float\n\t [[node sr_network_3/fully_connected/kernel/RMSProp/Initializer/ones (defined at C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\nOriginal stack trace for 'sr_network_3/fully_connected/kernel/RMSProp/Initializer/ones':\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 243, in <module>\n    prioritized_srdqn_runner = run_experiment.TrainRunner(LOG_PATH, create_prioritized_srdqn_agent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 553, in __init__\n    create_environment_fn)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 219, in __init__\n    summary_writer=self._summary_writer)\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 200, in create_prioritized_srdqn_agent\n    return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 15, in __init__\n    self._sr_train_op = self._build_sr_train_op()\n  File \"<ipython-input-6-dc351bfa4e8e>\", line 90, in _build_sr_train_op\n    return self.optimizer.minimize(tf.reduce_mean(loss))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 413, in minimize\n    name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 597, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\rmsprop.py\", line 124, in _create_slots\n    self._name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 1135, in _get_or_make_slot_with_initializer\n    var, initializer, shape, dtype, op_name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 164, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\slot_creator.py\", line 74, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\", line 1537, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\", line 905, in <lambda>\n    partition_info=partition_info)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py\", line 134, in __call__\n    return array_ops.ones(shape, dtype)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2572, in ones\n    output = fill(shape, constant(one, dtype=dtype), name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 171, in fill\n    result = gen_array_ops.fill(dims, value, name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 3602, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n  In call to configurable 'Runner' (<class 'dopamine.discrete_domains.run_experiment.Runner'>)\n  In call to configurable 'TrainRunner' (<class 'dopamine.discrete_domains.run_experiment.TrainRunner'>)"
     ]
    }
   ],
   "source": [
    "# @title Create the DQN with prioritized replay\n",
    "from dopamine.replay_memory import prioritized_replay_buffer\n",
    "import tensorflow as tf\n",
    "\n",
    "class PrioritizedSRDQNAgent(dqn_agent.DQNAgent):\n",
    "  def __init__(self, sess, num_actions):\n",
    "    \"\"\"This maintains all the DQN default argument values.\"\"\"\n",
    "    super().__init__(sess, num_actions, tf_device='/cpu:*')\n",
    "    self._replay_scheme = 'prioritized'\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        self._build_networks()\n",
    "\n",
    "        self._train_op = self._build_train_op()\n",
    "        self._sr_train_op = self._build_sr_train_op()\n",
    "        self._sync_qt_ops = self._build_sync_op()\n",
    "        \n",
    "    print('finished constructing')\n",
    "    self.online_convnet.summary()\n",
    "    self.sr_convnet.summary()\n",
    "        \n",
    "\n",
    "  def _build_networks(self):\n",
    "    \"\"\"Builds the Q-value network computations needed for acting and training.\n",
    "\n",
    "    These are:\n",
    "      self.online_convnet: For computing the current state's Q-values.\n",
    "      self.target_convnet: For computing the next state's target Q-values.\n",
    "      self.sr_convnet: For computing the sr for state-action pair\n",
    "      self._net_outputs: The actual Q-values.\n",
    "      self._q_argmax: The action maximizing the current state's Q-values.\n",
    "      self._replay_net_outputs: The replayed states' Q-values.\n",
    "      self._replay_next_target_net_outputs: The replayed next states' target\n",
    "        Q-values (see Mnih et al., 2015 for details).\n",
    "    \"\"\"\n",
    "\n",
    "    # _network_template instantiates the model and returns the network object.\n",
    "    # The network object can be used to generate different outputs in the graph.\n",
    "    # At each call to the network, the parameters will be reused.\n",
    "    self.online_convnet = self._create_network(name='Online')\n",
    "    self.target_convnet = self._create_network(name='Target')\n",
    "    self._net_outputs = self.online_convnet(self.state_ph)\n",
    "    # TODO(bellemare): Ties should be broken. They are unlikely to happen when\n",
    "    # using a deep network, but may affect performance with a linear\n",
    "    # approximation scheme.\n",
    "    self._q_argmax = tf.argmax(self._net_outputs.q_values, axis=1)[0]\n",
    "    self._replay_net_outputs = self.online_convnet(self._replay.transition['state'])\n",
    "    self._replay_next_target_net_outputs = self.target_convnet(\n",
    "        self._replay.transition['next_state'])\n",
    "    \n",
    "    self._q_argmax_sr = tf.argmax(self._net_outputs.q_values, axis=1)\n",
    "    self.sr_convnet = atari_lib.SRNetwork(self.num_actions, atari_lib.NATURE_DQN_STACK_SIZE)\n",
    "    # sr for states sampled\n",
    "    self._sr_net_outputs = self.sr_convnet(self._replay.transition['state'])\n",
    "    # sr for next_states sampled\n",
    "    self._sr_net_outputs_next = self.sr_convnet(self._replay.transition['next_state'])\n",
    "    # sr for current state and action\n",
    "    self._sr_net_curr_state = self.sr_convnet(self.state_ph)\n",
    "\n",
    "  def _build_replay_buffer(self, use_staging):\n",
    "    return prioritized_replay_buffer.WrappedPrioritizedReplayBuffer(\n",
    "        observation_shape=self.observation_shape,\n",
    "        stack_size=self.stack_size,\n",
    "        use_staging=use_staging,\n",
    "        update_horizon=self.update_horizon,\n",
    "        gamma=self.gamma,\n",
    "        observation_dtype=self.observation_dtype.as_numpy_dtype)\n",
    "  \n",
    "  def _build_sr_train_op(self):\n",
    "    feature = self._sr_net_outputs.feature\n",
    "    decoded_state = self._sr_net_outputs.decoded_state\n",
    "    \n",
    "    loss_ae = tf.compat.v1.losses.huber_loss(\n",
    "        self._replay.states, decoded_state, reduction=tf.losses.Reduction.NONE\n",
    "    )\n",
    "    srs = self._sr_net_outputs.sr_values\n",
    "    indices = tf.transpose(tf.stack([self._replay.actions, tf.constant([i for i in range(32)])]))\n",
    "    srs = tf.gather_nd(srs, indices)\n",
    "    \n",
    "    srs_next = self._sr_net_outputs_next.sr_values\n",
    "    indices_next = tf.transpose(tf.stack([self._replay.next_actions, tf.constant([i for i in range(32)])]))\n",
    "    srs_next = tf.gather_nd(srs_next, indices_next)\n",
    "    \n",
    "    assert feature.shape == srs_next.shape\n",
    "    assert srs.shape == feature.shape\n",
    "    \n",
    "    loss_sr = tf.compat.v1.losses.mean_squared_error(\n",
    "        srs, feature + self.gamma * srs_next\n",
    "    )\n",
    "    loss = loss_ae + loss_sr\n",
    "    return self.optimizer.minimize(tf.reduce_mean(loss))\n",
    "\n",
    "  def _build_train_op(self):\n",
    "    \"\"\"Builds a training op.\n",
    "    Returns:\n",
    "      train_op: An op performing one step of training from replay data.\n",
    "    \"\"\"\n",
    "    replay_action_one_hot = tf.one_hot(\n",
    "        self._replay.actions, self.num_actions, 1., 0., name='action_one_hot')\n",
    "    replay_chosen_q = tf.reduce_sum(\n",
    "        self._replay_net_outputs.q_values * replay_action_one_hot,\n",
    "        axis=1,\n",
    "        name='replay_chosen_q')\n",
    "    \n",
    "    # output from the SR network\n",
    "    # note that the back prop of the q-loss should not take into account\n",
    "    # the graph of the need term.\n",
    "    curr_action = tf.stop_gradient(self._q_argmax_sr)\n",
    "    sample_features = self._sr_net_outputs.feature\n",
    "    curr_sr = self._sr_net_curr_state.sr_values    \n",
    "    curr_sr = tf.gather_nd(curr_sr, curr_action)\n",
    "    need = tf.stop_gradient(\n",
    "        tf.tensordot(curr_sr, sample_features, axes=[[1], [1]])[0]\n",
    "    )\n",
    "    \n",
    "\n",
    "    target = tf.stop_gradient(self._build_target_q_op())\n",
    "    loss = tf.compat.v1.losses.huber_loss(\n",
    "        target, replay_chosen_q, reduction=tf.losses.Reduction.NONE)\n",
    "    # The original prioritized experience replay uses a linear exponent\n",
    "    # schedule 0.4 -> 1.0. Comparing the schedule to a fixed exponent of 0.5\n",
    "    # on 5 games (Asterix, Pong, Q*Bert, Seaquest, Space Invaders) suggested\n",
    "    # a fixed exponent actually performs better, except on Pong.\n",
    "    probs = self._replay.transition['sampling_probabilities']\n",
    "    loss_weights = 1.0 / tf.sqrt(probs + 1e-10)\n",
    "    loss_weights /= tf.reduce_max(loss_weights)\n",
    "\n",
    "    # Rainbow and prioritized replay are parametrized by an exponent alpha,\n",
    "    # but in both cases it is set to 0.5 - for simplicity's sake we leave it\n",
    "    # as is here, using the more direct tf.sqrt(). Taking the square root\n",
    "    # \"makes sense\", as we are dealing with a squared loss.\n",
    "    # Add a small nonzero value to the loss to avoid 0 priority items. While\n",
    "    # technically this may be okay, setting all items to 0 priority will cause\n",
    "    # troubles, and also result in 1.0 / 0.0 = NaN correction terms.\n",
    "    update_priorities_op = self._replay.tf_set_priority(\n",
    "        self._replay.indices, tf.sqrt(loss + 1e-10))\n",
    "\n",
    "    # Weight the loss by the inverse priorities.\n",
    "#     loss = loss_weights * loss * need\n",
    "    loss = loss_weights * loss\n",
    "    \n",
    "    assert need.shape == loss.shape\n",
    "    loss_need = need * loss\n",
    "    \n",
    "    with tf.control_dependencies([update_priorities_op]):\n",
    "      if self.summary_writer is not None:\n",
    "        with tf.compat.v1.variable_scope('Losses'):\n",
    "          tf.compat.v1.summary.scalar('HuberLoss', tf.reduce_mean(loss_need))\n",
    "      return self.optimizer.minimize(tf.reduce_mean(loss_need))\n",
    "\n",
    "  def _store_transition(self,\n",
    "                        last_observation,\n",
    "                        action,\n",
    "                        reward,\n",
    "                        is_terminal,\n",
    "                        priority=None):\n",
    "    priority = self._replay.memory.sum_tree.max_recorded_priority\n",
    "    if not self.eval_mode:\n",
    "      self._replay.add(last_observation, action, reward, is_terminal, priority)\n",
    "    \n",
    "  def _record_observation(self, observation):\n",
    "    \"\"\"Records an observation and update state.\n",
    "\n",
    "    Extracts a frame from the observation vector and overwrites the oldest\n",
    "    frame in the state buffer.\n",
    "\n",
    "    Args:\n",
    "      observation: numpy array, an observation from the environment.\n",
    "    \"\"\"\n",
    "    # Set current observation. We do the reshaping to handle environments\n",
    "    # without frame stacking.\n",
    "    self._observation = np.reshape(observation, self.observation_shape)\n",
    "    # Swap out the oldest frame with the current frame.\n",
    "    self.state = np.roll(self.state, -1, axis=-1)\n",
    "    self.state[0, ..., -1] = self._observation\n",
    "    \n",
    "  def _train_step(self):\n",
    "    \"\"\"Runs a single training step.\n",
    "\n",
    "    Runs a training op if both:\n",
    "      (1) A minimum number of frames have been added to the replay buffer.\n",
    "      (2) `training_steps` is a multiple of `update_period`.\n",
    "\n",
    "    Also, syncs weights from online to target network if training steps is a\n",
    "    multiple of target update period.\n",
    "    \"\"\"\n",
    "    # Run a train op at the rate of self.update_period if enough training steps\n",
    "    # have been run. This matches the Nature DQN behaviour.\n",
    "    if self._replay.memory.add_count > self.min_replay_history:\n",
    "      if self.training_steps % self.update_period == 0:\n",
    "        self._sess.run(self._train_op, {self.state_ph: self.state})\n",
    "        print(self._replay.states.shape)\n",
    "        print(self._replay.transition['state'].shape)\n",
    "        self._sess.run(self._sr_train_op)\n",
    "        if (self.summary_writer is not None and\n",
    "            self.training_steps > 0 and\n",
    "            self.training_steps % self.summary_writing_frequency == 0):\n",
    "          summary = self._sess.run(self._merged_summaries)\n",
    "          self.summary_writer.add_summary(summary, self.training_steps)\n",
    "\n",
    "      if self.training_steps % self.target_update_period == 0:\n",
    "        self._sess.run(self._sync_qt_ops)\n",
    "\n",
    "    self.training_steps += 1\n",
    "    \n",
    "def create_prioritized_srdqn_agent(sess, environment, summary_writer=None):\n",
    "  \"\"\"The Runner class will expect a function of this type to create an agent.\"\"\"\n",
    "  return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n",
    "\n",
    "prioritized_srdqn_config = \"\"\"\n",
    "import dopamine.discrete_domains.atari_lib\n",
    "import dopamine.discrete_domains.run_experiment\n",
    "import dopamine.agents.dqn.dqn_agent\n",
    "import dopamine.replay_memory.prioritized_replay_buffer\n",
    "import gin.tf.external_configurables\n",
    "\n",
    "DQNAgent.gamma = 0.99\n",
    "DQNAgent.update_horizon = 1\n",
    "DQNAgent.min_replay_history = 20000  # agent steps\n",
    "DQNAgent.update_period = 4\n",
    "DQNAgent.target_update_period = 8000  # agent steps\n",
    "DQNAgent.epsilon_train = 0.01\n",
    "DQNAgent.epsilon_eval = 0.001\n",
    "DQNAgent.epsilon_decay_period = 250000  # agent steps\n",
    "DQNAgent.tf_device = '/gpu:0'  # use '/cpu:*' for non-GPU version\n",
    "DQNAgent.optimizer = @tf.train.RMSPropOptimizer()\n",
    "\n",
    "tf.train.RMSPropOptimizer.learning_rate = 0.00025\n",
    "tf.train.RMSPropOptimizer.decay = 0.95\n",
    "tf.train.RMSPropOptimizer.momentum = 0.0\n",
    "tf.train.RMSPropOptimizer.epsilon = 0.00001\n",
    "tf.train.RMSPropOptimizer.centered = True\n",
    "\n",
    "atari_lib.create_atari_environment.game_name = '{}'\n",
    "# Sticky actions with probability 0.25, as suggested by (Machado et al., 2017).\n",
    "atari_lib.create_atari_environment.sticky_actions = True\n",
    "create_agent.agent_name = 'dqn'\n",
    "Runner.num_iterations = 200\n",
    "Runner.training_steps = 250000  # agent steps\n",
    "Runner.evaluation_steps = 125000  # agent steps\n",
    "Runner.max_steps_per_episode = 27000  # agent steps\n",
    "\n",
    "WrappedPrioritizedReplayBuffer.replay_capacity = 1000000\n",
    "WrappedPrioritizedReplayBuffer.batch_size = 32\n",
    "\"\"\".format(GAME)\n",
    "gin.parse_config(prioritized_srdqn_config, skip_unknown=False)\n",
    "\n",
    "# Create the runner class with this agent. We use very small numbers of steps\n",
    "# to terminate quickly, as this is mostly meant for demonstrating how one can\n",
    "# use the framework.\n",
    "prioritized_srdqn_runner = run_experiment.TrainRunner(LOG_PATH, create_prioritized_srdqn_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train agent, please be patient, may be a while...\n",
      "(32, 84, 84, 4) 19922 Episode length: 1450 Return: 2000.0\n",
      "(32, 84, 84, 4)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[451584,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_2/sr_network_1_1/fully_connected/MatMul_grad/MatMul_1 (defined at C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'gradients_2/sr_network_1_1/fully_connected/MatMul_grad/MatMul_1':\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-e6597709383f>\", line 242, in <module>\n    prioritized_srdqn_runner = run_experiment.TrainRunner(LOG_PATH, create_prioritized_srdqn_agent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 553, in __init__\n    create_environment_fn)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 219, in __init__\n    summary_writer=self._summary_writer)\n  File \"<ipython-input-4-e6597709383f>\", line 199, in create_prioritized_srdqn_agent\n    return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n  File \"<ipython-input-4-e6597709383f>\", line 15, in __init__\n    self._sr_train_op = self._build_sr_train_op()\n  File \"<ipython-input-4-e6597709383f>\", line 89, in _build_sr_train_op\n    return self.optimizer.minimize(tf.reduce_mean(loss))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 403, in minimize\n    grad_loss=grad_loss)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 512, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_impl.py\", line 158, in gradients\n    unconnected_gradients)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\", line 679, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\", line 350, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\", line 679, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\", line 1586, in _MatMulGrad\n    grad_b = gen_math_ops.mat_mul(a, grad, transpose_a=True)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'sr_network_1_1/fully_connected/MatMul', defined at:\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 35 identical lines from previous traceback]\n  File \"<ipython-input-4-e6597709383f>\", line 199, in create_prioritized_srdqn_agent\n    return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n  File \"<ipython-input-4-e6597709383f>\", line 12, in __init__\n    self._build_networks()\n  File \"<ipython-input-4-e6597709383f>\", line 52, in _build_networks\n    self._sr_net_outputs = self.sr_convnet(self._replay.transition['state'])\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\atari_lib.py\", line 258, in call\n    phi = self.dense_phi(phi)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\", line 1050, in call\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[451584,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradients_2/sr_network_1_1/fully_connected/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cba92581b23a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# @title Train MyRandomDQNAgent.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Will train agent, please be patient, may be a while...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprioritized_srdqn_runner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done training!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m       \u001b[0mstatistics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_one_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36m_run_one_iteration\u001b[1;34m(self, iteration)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mstatistics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miteration_statistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterationStatistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     num_episodes_train, average_reward_train, average_steps_per_second = (\n\u001b[1;32m--> 572\u001b[1;33m         self._run_train_phase(statistics))\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     self._save_tensorboard_summaries(iteration, num_episodes_train,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36m_run_train_phase\u001b[1;34m(self, statistics)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     number_steps, sum_returns, num_episodes = self._run_one_phase(\n\u001b[1;32m--> 400\u001b[1;33m         self._training_steps, statistics, 'train')\n\u001b[0m\u001b[0;32m    401\u001b[0m     \u001b[0maverage_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_returns\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'train_average_return'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maverage_return\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36m_run_one_phase\u001b[1;34m(self, min_steps, statistics, run_mode_str)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep_count\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m       \u001b[0mepisode_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_one_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m       statistics.append({\n\u001b[0;32m    370\u001b[0m           \u001b[1;34m'{}_episode_lengths'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_mode_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepisode_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\u001b[0m in \u001b[0;36m_run_one_episode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_terminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\agents\\dqn\\dqn_agent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, reward, observation)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_transition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_observation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e6597709383f>\u001b[0m in \u001b[0;36m_train_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransition\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sr_train_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         if (self.summary_writer is not None and\n\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_steps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[451584,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_2/sr_network_1_1/fully_connected/MatMul_grad/MatMul_1 (defined at C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'gradients_2/sr_network_1_1/fully_connected/MatMul_grad/MatMul_1':\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-e6597709383f>\", line 242, in <module>\n    prioritized_srdqn_runner = run_experiment.TrainRunner(LOG_PATH, create_prioritized_srdqn_agent)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 553, in __init__\n    create_environment_fn)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\gin\\config.py\", line 1046, in gin_wrapper\n    return fn(*new_args, **new_kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\run_experiment.py\", line 219, in __init__\n    summary_writer=self._summary_writer)\n  File \"<ipython-input-4-e6597709383f>\", line 199, in create_prioritized_srdqn_agent\n    return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n  File \"<ipython-input-4-e6597709383f>\", line 15, in __init__\n    self._sr_train_op = self._build_sr_train_op()\n  File \"<ipython-input-4-e6597709383f>\", line 89, in _build_sr_train_op\n    return self.optimizer.minimize(tf.reduce_mean(loss))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 403, in minimize\n    grad_loss=grad_loss)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py\", line 512, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_impl.py\", line 158, in gradients\n    unconnected_gradients)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\", line 679, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\", line 350, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\", line 679, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\", line 1586, in _MatMulGrad\n    grad_b = gen_math_ops.mat_mul(a, grad, transpose_a=True)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'sr_network_1_1/fully_connected/MatMul', defined at:\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 35 identical lines from previous traceback]\n  File \"<ipython-input-4-e6597709383f>\", line 199, in create_prioritized_srdqn_agent\n    return PrioritizedSRDQNAgent(sess, num_actions=environment.action_space.n)\n  File \"<ipython-input-4-e6597709383f>\", line 12, in __init__\n    self._build_networks()\n  File \"<ipython-input-4-e6597709383f>\", line 52, in _build_networks\n    self._sr_net_outputs = self.sr_convnet(self._replay.transition['state'])\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\dopamine\\discrete_domains\\atari_lib.py\", line 258, in call\n    phi = self.dense_phi(phi)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\", line 1050, in call\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\apple\\anaconda3\\envs\\dopamine-need\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# @title Train MyRandomDQNAgent.\n",
    "print('Will train agent, please be patient, may be a while...')\n",
    "prioritized_srdqn_runner.run_experiment()\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant([0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = tf.constant([[[-100, -1], [-1, -1], [-1, -1], [-1, -1]], [[-1, -1], [-1, -1], [-1, -1000], [-1, -1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -100,    -1],\n",
       "        [   -1,    -1],\n",
       "        [   -1,    -1],\n",
       "        [   -1,    -1]],\n",
       "\n",
       "       [[   -1,    -1],\n",
       "        [   -1,    -1],\n",
       "        [   -1, -1000],\n",
       "        [   -1,    -1]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = tf.transpose(t2)\n",
    "# t3 = tf.gather_nd(t2, [[1, 0], [1, 1], [1,2]])\n",
    "tf.keras.backend.get_value(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,   -1],\n",
       "       [  -1,   -1],\n",
       "       [  -1,   -1],\n",
       "       [  -1,   -1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.get_value(tf.gather_nd(t2, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot_3:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot([1, 2, 0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = tf.constant([i for i in range(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = tf.constant([0 for i in range(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 1,  0],\n",
       "       [ 2,  0],\n",
       "       [ 3,  0],\n",
       "       [ 4,  0],\n",
       "       [ 5,  0],\n",
       "       [ 6,  0],\n",
       "       [ 7,  0],\n",
       "       [ 8,  0],\n",
       "       [ 9,  0],\n",
       "       [10,  0],\n",
       "       [11,  0],\n",
       "       [12,  0],\n",
       "       [13,  0],\n",
       "       [14,  0],\n",
       "       [15,  0],\n",
       "       [16,  0],\n",
       "       [17,  0],\n",
       "       [18,  0],\n",
       "       [19,  0],\n",
       "       [20,  0],\n",
       "       [21,  0],\n",
       "       [22,  0],\n",
       "       [23,  0],\n",
       "       [24,  0],\n",
       "       [25,  0],\n",
       "       [26,  0],\n",
       "       [27,  0],\n",
       "       [28,  0],\n",
       "       [29,  0],\n",
       "       [30,  0],\n",
       "       [31,  0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.get_value(tf.transpose(tf.stack([all, ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dopamine-need",
   "language": "python",
   "name": "dopamine-need"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
